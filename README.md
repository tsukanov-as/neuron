# neuron

Классификатор, моделирующий импульсную нейронную сеть прямого распространения.
В сети два слоя:
* входной - признаки
* выходной - классы

Каждая связь в сети пропускает импульс с вероятностью, рассчитанной по теореме Байеса:
`W[n,m]=Pr(Class[n]|Feature[m])`  
Выходной нейрон срабатывает с вероятностью:  
`Pr(Class[n]|W[n,1] + W[n,2] + ... + W[n,m])`  
рассчитанной по теореме сложения вероятностей совместных независимых событий:  
`Pr(A+B)=Pr(A)+Pr(B)-Pr(A*B)`

Предполагается, что сработавший входной нейрон выдает пачку импульсов фиксированного размера. Дальше каждый импульс распространяется по связям с соответствующими вероятностями. Выходной нейрон суммирует пришедшие импульсы за некоторый промежуток времени (пришедшие одновременно считаются как один) и срабатывает с вероятностью сумма/порог, где порог равен размеру пачки. Обучение сети гипотетически может происходить путем увеличения на константу веса сработавших связей целевого класса (прямолинейный сбор статистики), при этом периодически вес каждой связи сети должен уменьшаться на ту же константу (забывание). Нейрон тоже должен копить статистику своих срабатываний, отношение веса исходящей связи к весу нейрона дает искомую вероятность пропуска импульса по теореме Байеса. Вес нейрона аналогично связям периодически уменьшается.
Обучение многослойной сети гипотетически возможно путем обратного распространения награды (увеличение веса сработавших связей).

```sh
$ git clone https://github.com/tsukanov-as/neuron.git && cd neuron
$ go test -v ./...
```
